{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["pUWbd2EWEurC","rQnDyDwDeN8a","s52z-cYK7ErM"],"gpuType":"V100","mount_file_id":"1s_epZW1eTIhz_lzvW4dIy37yvIyOG1ME","authorship_tag":"ABX9TyMwJlir/OwG1i0EvuQD29IP"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"gpuClass":"standard"},"cells":[{"cell_type":"markdown","metadata":{"id":"4AorqgELCu7y"},"source":["# **Copy Data from Drive to Colab Hard**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"viyccn3xC8EK"},"outputs":[],"source":["!cp /content/drive/MyDrive/Masoudi/dataset.zip ."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vV0_n-cJUPKK"},"outputs":[],"source":["!unzip -qq dataset.zip"]},{"cell_type":"code","source":["!cp /content/drive/MyDrive/Masoudi/4.zip .\n","!unzip -qq /content/4.zip"],"metadata":{"id":"jXxcW6pNlNMW","executionInfo":{"status":"ok","timestamp":1682377100371,"user_tz":-210,"elapsed":25850,"user":{"displayName":"AIA Team","userId":"16477440184016990512"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["!cp /content/drive/MyDrive/Masoudi/empty.zip /content"],"metadata":{"id":"nfZz4jlr8wgE","executionInfo":{"status":"ok","timestamp":1682377100371,"user_tz":-210,"elapsed":13,"user":{"displayName":"AIA Team","userId":"16477440184016990512"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["!unzip -qq empty.zip -d  /content/example/test_data"],"metadata":{"id":"lyw92Cv34rQe","executionInfo":{"status":"ok","timestamp":1682377100371,"user_tz":-210,"elapsed":12,"user":{"displayName":"AIA Team","userId":"16477440184016990512"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["!unzip -qq empty.zip -d  /content/example/training_data"],"metadata":{"id":"MlxDq6lC49BW","executionInfo":{"status":"ok","timestamp":1682377100372,"user_tz":-210,"elapsed":13,"user":{"displayName":"AIA Team","userId":"16477440184016990512"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pUWbd2EWEurC"},"source":["# **util: Helper Code**"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"0FQCCq2sEyEi","executionInfo":{"status":"ok","timestamp":1682377100839,"user_tz":-210,"elapsed":479,"user":{"displayName":"AIA Team","userId":"16477440184016990512"}}},"outputs":[],"source":["#!/usr/bin/env python\n","\n","# Do *not* edit this script.\n","# These are helper functions that you can use with your code.\n","# Check the example code to see how to import these functions to your code.\n","\n","import os, numpy as np, scipy as sp, scipy.io\n","\n","### Challenge data I/O functions\n","\n","# Find the folders with data files.\n","def find_data_folders(root_folder):\n","    data_folders = list()\n","    for x in os.listdir(root_folder):\n","        data_folder = os.path.join(root_folder, x)\n","        if os.path.isdir(data_folder):\n","            data_folders.append(x)\n","    return sorted(data_folders)\n","\n","def load_challenge_data(data_folder, patient_id):\n","    # Define file location.\n","    patient_metadata_file = os.path.join(data_folder, patient_id, patient_id + '.txt')\n","    recording_metadata_file = os.path.join(data_folder, patient_id, patient_id + '.tsv')\n","\n","    # Load non-recording data.\n","    patient_metadata = load_text_file(patient_metadata_file)\n","    recording_metadata = load_text_file(recording_metadata_file)\n","\n","    # Load recordings.\n","    recordings = list()\n","    recording_ids = get_recording_ids(recording_metadata)\n","    for recording_id in recording_ids:\n","        if recording_id != 'nan':\n","            recording_location = os.path.join(data_folder, patient_id, recording_id)\n","            recording_data, sampling_frequency, channels = load_recording(recording_location)\n","        else:\n","            recording_data = None\n","            sampling_frequency = None\n","            channels = None\n","        recordings.append((recording_data, sampling_frequency, channels))\n","\n","    return patient_metadata, recording_metadata, recordings\n","\n","# Load the WFDB data for the Challenge (but not all possible WFDB files).\n","def load_recording(record_name):\n","    # Allow either the record name or the header filename.\n","    root, ext = os.path.splitext(record_name)\n","    if ext=='':\n","        header_file = record_name + '.hea'\n","    else:\n","        header_file = record_name\n","\n","    # Load the header file.\n","    if not os.path.isfile(header_file):\n","        raise FileNotFoundError('{} recording not found.'.format(record_name))\n","\n","    with open(header_file, 'r') as f:\n","        header = [l.strip() for l in f.readlines() if l.strip()]\n","\n","    # Parse the header file.\n","    record_name = None\n","    num_signals = None\n","    sampling_frequency = None\n","    num_samples = None\n","    signal_files = list()\n","    gains = list()\n","    offsets = list()\n","    channels = list()\n","    initial_values = list()\n","    checksums = list()\n","\n","    for i, l in enumerate(header):\n","        arrs = [arr.strip() for arr in l.split(' ')]\n","        # Parse the record line.\n","        if i==0:\n","            record_name = arrs[0]\n","            num_signals = int(arrs[1])\n","            sampling_frequency = float(arrs[2])\n","            num_samples = int(arrs[3])\n","        # Parse the signal specification lines.\n","        else:\n","            signal_file = arrs[0]\n","            gain = float(arrs[2].split('/')[0])\n","            offset = int(arrs[4])\n","            initial_value = int(arrs[5])\n","            checksum = int(arrs[6])\n","            channel = arrs[8]\n","            signal_files.append(signal_file)\n","            gains.append(gain)\n","            offsets.append(offset)\n","            initial_values.append(initial_value)\n","            checksums.append(checksum)\n","            channels.append(channel)\n","\n","    # Check that the header file only references one signal file. WFDB format  allows for multiple signal files, but we have not\n","    # implemented that here for simplicity.\n","    num_signal_files = len(set(signal_files))\n","    if num_signal_files!=1:\n","        raise NotImplementedError('The header file {}'.format(header_file) \\\n","            + ' references {} signal files; one signal file expected.'.format(num_signal_files))\n","\n","    # Load the signal file.\n","    head, tail = os.path.split(header_file)\n","    signal_file = os.path.join(head, list(signal_files)[0])\n","    data = np.asarray(sp.io.loadmat(signal_file)['val'])\n","\n","    # Check that the dimensions of the signal data in the signal file is consistent with the dimensions for the signal data given\n","    # in the header file.\n","    num_channels = len(channels)\n","    if np.shape(data)!=(num_channels, num_samples):\n","        raise ValueError('The header file {}'.format(header_file) \\\n","            + ' is inconsistent with the dimensions of the signal file.')\n","\n","    # Check that the initial value and checksums for the signal data in the signal file are consistent with the initial value and\n","    # checksums for the signal data given in the header file.\n","    for i in range(num_channels):\n","        if data[i, 0]!=initial_values[i]:\n","            raise ValueError('The initial value in header file {}'.format(header_file) \\\n","                + ' is inconsistent with the initial value for channel'.format(channels[i]))\n","        if np.sum(data[i, :])!=checksums[i]:\n","            raise ValueError('The checksum in header file {}'.format(header_file) \\\n","                + ' is inconsistent with the initial value for channel'.format(channels[i]))\n","\n","    # Rescale the signal data using the ADC gains and ADC offsets.\n","    rescaled_data = np.zeros(np.shape(data), dtype=np.float32)\n","    for i in range(num_channels):\n","        rescaled_data[i, :] = (data[i, :]-offsets[i])/gains[i]\n","\n","    return rescaled_data, sampling_frequency, channels\n","\n","# Reorder/reselect the channels.\n","def reorder_recording_channels(current_data, current_channels, reordered_channels):\n","    if current_channels == reordered_channels:\n","        return current_data\n","    else:\n","        indices = list()\n","        for channel in reordered_channels:\n","            if channel in current_channels:\n","                i = current_channels.index(channel)\n","                indices.append(i)\n","        num_channels = len(reordered_channels)\n","        num_samples = np.shape(current_data)[1]\n","        reordered_data = np.zeros((num_channels, num_samples))\n","        reordered_data[:, :] = current_data[indices, :]\n","        return reordered_data\n","\n","### Helper Challenge data I/O functions\n","\n","# Load text file as a string.\n","def load_text_file(filename):\n","    with open(filename, 'r') as f:\n","        data = f.read()\n","    return data\n","\n","# Get a variable from the patient metadata.\n","def get_variable(text, variable_name, variable_type, preserve_nan=True):\n","    variable = None\n","    for l in text.split('\\n'):\n","        if l.startswith(variable_name):\n","            variable = l.split(':')[1].strip()\n","            if preserve_nan and variable.lower() == 'nan':\n","                variable = float('nan')\n","            else:\n","                variable = variable_type(variable)\n","            return variable\n","\n","# Get a column from the recording metadata.\n","def get_column(string, column, variable_type, sep='\\t'):\n","    variables = list()\n","    for i, l in enumerate(string.split('\\n')):\n","        arrs = [arr.strip() for arr in l.split(sep) if arr.strip()]\n","        if i==0:\n","            column_index = arrs.index(column)\n","        elif arrs:\n","            variable = arrs[column_index]\n","            variable = variable_type(variable)\n","            variables.append(variable)\n","    return np.asarray(variables)\n","\n","# Get the patient ID variable from the patient data.\n","def get_patient_id(string):\n","    return get_variable(string, 'Patient', str)\n","\n","# Get the age variable (in years) from the patient data.\n","def get_age(string):\n","    return get_variable(string, 'Age', int)\n","\n","# Get the sex variable from the patient data.\n","def get_sex(string):\n","    return get_variable(string, 'Sex', str)\n","\n","# Get the ROSC variable (in minutes) from the patient data.\n","def get_rosc(string):\n","    return get_variable(string, 'ROSC', int)\n","\n","# Get the OHCA variable from the patient data.\n","def get_ohca(string):\n","    return get_variable(string, 'OHCA', bool)\n","\n","# Get the VFib variable from the patient data.\n","def get_vfib(string):\n","    return get_variable(string, 'VFib', bool)\n","\n","# Get the TTM variable (in Celsius) from the patient data.\n","def get_ttm(string):\n","    return get_variable(string, 'TTM', int)\n","\n","# Get the Outcome variable from the patient data.\n","def get_outcome(string):\n","    variable = get_variable(string, 'Outcome', str)\n","    if variable is None or is_nan(variable):\n","        raise ValueError('No outcome available. Is your code trying to load labels from the hidden data?')\n","    if variable == 'Good':\n","        variable = 0\n","    elif variable == 'Poor':\n","        variable = 1\n","    return variable\n","\n","# Get the Outcome probability variable from the patient data.\n","def get_outcome_probability(string):\n","    variable = sanitize_scalar_value(get_variable(string, 'Outcome probability', str))\n","    if variable is None or is_nan(variable):\n","        raise ValueError('No outcome available. Is your code trying to load labels from the hidden data?')\n","    return variable\n","\n","# Get the CPC variable from the patient data.\n","def get_cpc(string):\n","    variable = sanitize_scalar_value(get_variable(string, 'CPC', str))\n","    if variable is None or is_nan(variable):\n","        raise ValueError('No CPC score available. Is your code trying to load labels from the hidden data?')\n","    return variable\n","\n","# Get the hour number column from the patient data.\n","def get_hours(string):\n","    return get_column(string, 'Hour', int)\n","\n","# Get the time column from the patient data.\n","def get_times(string):\n","    return get_column(string, 'Time', str)\n","\n","# Get the quality score column from the patient data.\n","def get_quality_scores(string):\n","    return get_column(string, 'Quality', float)\n","\n","# Get the recording IDs column from the patient data.\n","def get_recording_ids(string):\n","    return get_column(string, 'Record', str)\n","\n","### Challenge label and output I/O functions\n","\n","# Load the Challenge labels for one file.\n","def load_challenge_label(string):\n","    if os.path.isfile(string):\n","        string = load_text_file(string)\n","\n","    outcome = get_outcome(string)\n","    cpc = get_cpc(string)\n","\n","    return outcome, cpc\n","\n","# Load the Challenge labels for all of the files in a folder.\n","def load_challenge_labels(folder):\n","    patient_folders = find_data_folders(folder)\n","    num_patients = len(patient_folders)\n","\n","    patient_ids = list()\n","    outcomes = np.zeros(num_patients, dtype=np.bool_)\n","    cpcs = np.zeros(num_patients, dtype=np.float64)\n","\n","    for i in range(num_patients):\n","        patient_metadata_file = os.path.join(folder, patient_folders[i], patient_folders[i] + '.txt')\n","        patient_metadata = load_text_file(patient_metadata_file)\n","\n","        patient_ids.append(get_patient_id(patient_metadata))\n","        outcomes[i] = get_outcome(patient_metadata)\n","        cpcs[i] = get_cpc(patient_metadata)\n","\n","    return patient_ids, outcomes, cpcs\n","\n","# Save the Challenge outputs for one file.\n","def save_challenge_outputs(filename, patient_id, outcome, outcome_probability, cpc):\n","    # Sanitize values, e.g., in case they are a singleton array.\n","    outcome = sanitize_boolean_value(outcome)\n","    outcome_probability = sanitize_scalar_value(outcome_probability)\n","    cpc = sanitize_scalar_value(cpc)\n","\n","    # Format Challenge outputs.\n","    patient_string = 'Patient: {}'.format(patient_id)\n","    if outcome == 0:\n","        outcome = 'Good'\n","    elif outcome == 1:\n","        outcome = 'Poor'\n","    outcome_string = 'Outcome: {}'.format(outcome)\n","    outcome_probability_string = 'Outcome probability: {:.3f}'.format(float(outcome_probability))\n","    cpc_string = 'CPC: {:.3f}'.format(int(float(cpc)) if is_integer(cpc) else float(cpc))\n","    output_string = patient_string + '\\n' + \\\n","        outcome_string + '\\n' + outcome_probability_string + '\\n' + cpc_string + '\\n'\n","\n","    # Write the Challenge outputs.\n","    if filename is not None:\n","        with open(filename, 'w') as f:\n","            f.write(output_string)\n","\n","    return output_string\n","\n","# Load the Challenge outputs for one file.\n","def load_challenge_output(string):\n","    if os.path.isfile(string):\n","        string = load_text_file(string)\n","\n","    patient_id = get_patient_id(string)\n","    outcome = get_outcome(string)\n","    outcome_probability = get_outcome_probability(string)\n","    cpc = get_cpc(string)\n","\n","    return patient_id, outcome, outcome_probability, cpc\n","\n","# Load the Challenge outputs for all of the files in folder.\n","def load_challenge_outputs(folder, patient_ids):\n","    num_patients = len(patient_ids)\n","    outcomes = np.zeros(num_patients, dtype=np.bool_)\n","    outcome_probabilities = np.zeros(num_patients, dtype=np.float64)\n","    cpcs = np.zeros(num_patients, dtype=np.float64)\n","\n","    for i in range(num_patients):\n","        output_file = os.path.join(folder, patient_ids[i], patient_ids[i] + '.txt')\n","        patient_id, outcome, outcome_probability, cpc = load_challenge_output(output_file)\n","        outcomes[i] = outcome\n","        outcome_probabilities[i] = outcome_probability\n","        cpcs[i] = cpc\n","\n","    return outcomes, outcome_probabilities, cpcs\n","\n","### Other helper functions\n","\n","# Check if a variable is a number or represents a number.\n","def is_number(x):\n","    try:\n","        float(x)\n","        return True\n","    except (ValueError, TypeError):\n","        return False\n","\n","# Check if a variable is an integer or represents an integer.\n","def is_integer(x):\n","    if is_number(x):\n","        return float(x).is_integer()\n","    else:\n","        return False\n","\n","# Check if a variable is a finite number or represents a finite number.\n","def is_finite_number(x):\n","    if is_number(x):\n","        return np.isfinite(float(x))\n","    else:\n","        return False\n","\n","# Check if a variable is a NaN (not a number) or represents a NaN.\n","def is_nan(x):\n","    if is_number(x):\n","        return np.isnan(float(x))\n","    else:\n","        return False\n","\n","# Remove any quotes, brackets (for singleton arrays), and/or invisible characters.\n","def remove_extra_characters(x):\n","    return str(x).replace('\"', '').replace(\"'\", \"\").replace('[', '').replace(']', '').replace(' ', '').strip()\n","\n","# Sanitize boolean values, e.g., from the Challenge outputs.\n","def sanitize_boolean_value(x):\n","    x = remove_extra_characters(x)\n","    if (is_finite_number(x) and float(x)==0) or (x in ('False', 'false', 'F', 'f')):\n","        return 0\n","    elif (is_finite_number(x) and float(x)==1) or (x in ('True', 'true', 'T', 't')):\n","        return 1\n","    else:\n","        return float('nan')\n","\n","# Santize scalar values, e.g., from the Challenge outputs.\n","def sanitize_scalar_value(x):\n","    x = remove_extra_characters(x)\n","    if is_number(x):\n","        return float(x)\n","    else:\n","        return float('nan')"]},{"cell_type":"markdown","metadata":{"id":"rQnDyDwDeN8a"},"source":["# **util: getFeatures function**"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8765,"status":"ok","timestamp":1682377109125,"user":{"displayName":"AIA Team","userId":"16477440184016990512"},"user_tz":-210},"id":"za_BkvQFe_QT","outputId":"af7d383d-28c4-4452-8a10-0a02a4b7bc3e"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/7.6 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.3/7.6 MB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/7.6 MB\u001b[0m \u001b[31m29.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━\u001b[0m \u001b[32m6.2/7.6 MB\u001b[0m \u001b[31m57.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m63.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m42.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}],"source":["!pip install -q mne"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"IJt7bvayeSKI","executionInfo":{"status":"ok","timestamp":1682377111775,"user_tz":-210,"elapsed":2652,"user":{"displayName":"AIA Team","userId":"16477440184016990512"}}},"outputs":[],"source":["import mne\n","from sklearn.preprocessing import StandardScaler\n","def get_features(patient_metadata, recording_metadata, recording_data):\n","    # Extract features from the patient metadata.\n","    age = get_age(patient_metadata)\n","    sex = get_sex(patient_metadata)\n","    rosc = get_rosc(patient_metadata)\n","    ohca = get_ohca(patient_metadata)\n","    vfib = get_vfib(patient_metadata)\n","    ttm = get_ttm(patient_metadata)\n","\n","    # Use one-hot encoding for sex; add more variables\n","    sex_features = np.zeros(2, dtype=int)\n","    if sex == 'Female':\n","        female = 1\n","        male   = 0\n","        other  = 0\n","    elif sex == 'Male':\n","        female = 0\n","        male   = 1\n","        other  = 0\n","    else:\n","        female = 0\n","        male   = 0\n","        other  = 1\n","\n","    # Combine the patient features.\n","    patient_features = np.array([age, female, male, other, rosc, ohca, vfib, ttm])\n","\n","    # Extract features from the recording data and metadata.\n","    channels = ['Fp1-F7', 'F7-T3', 'T3-T5', 'T5-O1', 'Fp2-F8', 'F8-T4', 'T4-T6', 'T6-O2', 'Fp1-F3',\n","                'F3-C3', 'C3-P3', 'P3-O1', 'Fp2-F4', 'F4-C4', 'C4-P4', 'P4-O2', 'Fz-Cz', 'Cz-Pz']\n","    num_channels = len(channels)\n","    num_recordings = len(recording_data)\n","    print('LENGTH OF RECORDED DATASET', num_recordings)\n","\n","    # Compute mean and standard deviation for each channel for each recording.\n","    available_signal_data = list()\n","    for i in range(num_recordings):\n","        signal_data, sampling_frequency, signal_channels = recording_data[i]\n","        if signal_data is not None:\n","            signal_data = reorder_recording_channels(signal_data, signal_channels, channels) # Reorder the channels in the signal data, as needed, for consistency across different recordings.\n","            available_signal_data.append(signal_data)\n","\n","    if len(available_signal_data) > 0:\n","        available_signal_data = np.hstack(available_signal_data)\n","        signal_mean = np.nanmean(available_signal_data, axis=1)\n","        signal_std  = np.nanstd(available_signal_data, axis=1)\n","    else:\n","        signal_mean = float('nan') * np.ones(num_channels)\n","        signal_std  = float('nan') * np.ones(num_channels)\n","\n","    # Compute the power spectral density for the delta, theta, alpha, and beta frequency bands for each channel of the most\n","    # recent recording.\n","    index = None\n","    for i in reversed(range(num_recordings)):\n","        signal_data, sampling_frequency, signal_channels = recording_data[i]\n","        if signal_data is not None:\n","            index = i\n","            break\n","\n","    if index is not None:\n","        signal_data, sampling_frequency, signal_channels = recording_data[index]\n","        signal_data = reorder_recording_channels(signal_data, signal_channels, channels) # Reorder the channels in the signal data, as needed, for consistency across different recordings.\n","\n","        delta_psd, _ = mne.time_frequency.psd_array_welch(signal_data, sfreq=sampling_frequency,  fmin=0.5,  fmax=8.0, verbose=False)\n","        theta_psd, _ = mne.time_frequency.psd_array_welch(signal_data, sfreq=sampling_frequency,  fmin=4.0,  fmax=8.0, verbose=False)\n","        alpha_psd, _ = mne.time_frequency.psd_array_welch(signal_data, sfreq=sampling_frequency,  fmin=8.0, fmax=12.0, verbose=False)\n","        beta_psd,  _ = mne.time_frequency.psd_array_welch(signal_data, sfreq=sampling_frequency, fmin=12.0, fmax=30.0, verbose=False)\n","\n","        delta_psd_mean = np.nanmean(delta_psd, axis=1)\n","        theta_psd_mean = np.nanmean(theta_psd, axis=1)\n","        alpha_psd_mean = np.nanmean(alpha_psd, axis=1)\n","        beta_psd_mean  = np.nanmean(beta_psd,  axis=1)\n","\n","        quality_score = get_quality_scores(recording_metadata)[index]\n","    else:\n","        delta_psd_mean = theta_psd_mean = alpha_psd_mean = beta_psd_mean = float('nan') * np.ones(num_channels)\n","        quality_score = float('nan')\n","\n","    recording_features = np.hstack((signal_mean, signal_std, delta_psd_mean, theta_psd_mean, alpha_psd_mean, beta_psd_mean, quality_score))\n","\n","    # Combine the features from the patient metadata and the recording data and metadata.\n","    features = np.hstack((patient_features, recording_features))\n","\n","    return features"]},{"cell_type":"markdown","source":["# **Generate STFT**"],"metadata":{"id":"QA4ENAeJPwfp"}},{"cell_type":"code","source":["!rm -r /content/example/training_data"],"metadata":{"id":"MdJMG1syLrOP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!cp -r /content/i-care-international-cardiac-arrest-research-consortium-database-1.0/training /content/example"],"metadata":{"id":"qN9Zyll6SZtc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# rename training to training_data"],"metadata":{"id":"e7YeHr2LLv83"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%cd /content/example"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"x0Ec8S9ulMv6","executionInfo":{"status":"ok","timestamp":1682270065836,"user_tz":-210,"elapsed":565,"user":{"displayName":"AIA Team","userId":"16477440184016990512"}},"outputId":"eac5e32d-9f03-4407-81d9-ee6771064173"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/example\n"]}]},{"cell_type":"code","execution_count":9,"metadata":{"id":"npLIgW_gQDiU","executionInfo":{"status":"ok","timestamp":1682377111775,"user_tz":-210,"elapsed":3,"user":{"displayName":"AIA Team","userId":"16477440184016990512"}}},"outputs":[],"source":["data_folder = \"/content/example/training_data\"\n","model_folder = \"/content/example/model\""]},{"cell_type":"code","source":["os.makedirs(model_folder, exist_ok=True)"],"metadata":{"id":"oMQBYghZgJoP","executionInfo":{"status":"ok","timestamp":1682377424395,"user_tz":-210,"elapsed":324,"user":{"displayName":"AIA Team","userId":"16477440184016990512"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["training = os.listdir(data_folder)\n","sub_root_mat = []\n","for x in training:\n","  p = os.path.join(data_folder,x)\n","  p1 = os.listdir(p)\n","  for y in p1:\n","    z = os.path.join(p,y)\n","    if z.endswith('.mat'):\n","      sub_root_mat.append(z) "],"metadata":{"id":"QWDqBCnxNGMQ","executionInfo":{"status":"ok","timestamp":1682377432427,"user_tz":-210,"elapsed":1,"user":{"displayName":"AIA Team","userId":"16477440184016990512"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["from scipy.io import loadmat\n","EEG_data = []\n","EEG_label = []\n","for x in sub_root_mat:\n","  a1 = x.split('/')\n","  folder_id = a1[-2]\n","  patient_metadata, recording_metadata, recording_data = load_challenge_data(data_folder,folder_id)\n","  current_outcome = get_outcome(patient_metadata)\n","  EEG_label.append(current_outcome)\n","  EEG_data.append(loadmat(x)['val'])"],"metadata":{"id":"S5LRgsrPO-Tn","executionInfo":{"status":"ok","timestamp":1682377566381,"user_tz":-210,"elapsed":109011,"user":{"displayName":"AIA Team","userId":"16477440184016990512"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["EEG_data = np.array(EEG_data)\n","EEG_label = np.array(EEG_label)"],"metadata":{"id":"L2iyYTfkQnum","executionInfo":{"status":"ok","timestamp":1682377815277,"user_tz":-210,"elapsed":407,"user":{"displayName":"AIA Team","userId":"16477440184016990512"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["from keras.utils import to_categorical\n","from sklearn.preprocessing import OneHotEncoder\n","\n","\n","enc = OneHotEncoder(sparse_output=False)\n","target_total1 = enc.fit_transform(EEG_label.reshape(-1,1))\n","target_total1 = np.array(target_total1)\n","print(target_total1.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UUjeZxFcPgp5","executionInfo":{"status":"ok","timestamp":1682377822739,"user_tz":-210,"elapsed":4243,"user":{"displayName":"AIA Team","userId":"16477440184016990512"}},"outputId":"16dd02a6-c9b9-4c5b-c5c0-9558066ee9c6"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["(529, 2)\n"]}]},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","X_train, X_test, y_train, y_test = train_test_split(EEG_data,target_total1, test_size=0.2, random_state=21)\n","print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"k2eRphQ4Q2hI","executionInfo":{"status":"ok","timestamp":1682377822739,"user_tz":-210,"elapsed":4,"user":{"displayName":"AIA Team","userId":"16477440184016990512"}},"outputId":"bcf84c37-0f70-41c0-84de-96b45b8a6b87"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["(423, 18, 30000) (106, 18, 30000) (423, 2) (106, 2)\n"]}]},{"cell_type":"markdown","source":["# **Model**"],"metadata":{"id":"kaBkzrvutVV0"}},{"cell_type":"code","source":["from tensorflow import keras\n","from keras.callbacks import CSVLogger, ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n","\n","def _inception_module( input_tensor, stride=1, activation='linear'):\n","\n","        if use_bottleneck and int(input_tensor.shape[-1]) > 1:\n","            input_inception = keras.layers.Conv1D(filters=bottleneck_size, kernel_size=1,\n","                                                  padding='same', activation=activation, use_bias=False)(input_tensor)\n","        else:\n","            input_inception = input_tensor\n","\n","        kernel_size_s = [kernel_size // (2 ** i) for i in range(3)]\n","\n","        conv_list = []\n","\n","        for i in range(len(kernel_size_s)):\n","            conv_list.append(keras.layers.Conv1D(filters=nb_filters, kernel_size=kernel_size_s[i],\n","                                                 strides=stride, padding='same', activation=activation, use_bias=False)(\n","                input_inception))\n","\n","        max_pool_1 = keras.layers.MaxPool1D(pool_size=3, strides=stride, padding='same')(input_tensor)\n","\n","        conv_6 = keras.layers.Conv1D(filters=nb_filters, kernel_size=1,\n","                                     padding='same', activation=activation, use_bias=False)(max_pool_1)\n","\n","        conv_list.append(conv_6)\n","\n","        x = keras.layers.Concatenate(axis=2)(conv_list)\n","        x = keras.layers.BatchNormalization()(x)\n","        x = keras.layers.Activation(activation='relu')(x)\n","        return x\n","\n","def _shortcut_layer( input_tensor, out_tensor):\n","      shortcut_y = keras.layers.Conv1D(filters=int(out_tensor.shape[-1]), kernel_size=1,\n","                                         padding='same', use_bias=False)(input_tensor)\n","      shortcut_y = keras.layers.BatchNormalization()(shortcut_y)\n","\n","      x = keras.layers.Add()([shortcut_y, out_tensor])\n","      x = keras.layers.Activation('relu')(x)\n","      return x\n","\n","def build_model( input_shape, nb_classes):\n","      input_layer = keras.layers.Input(input_shape)\n","\n","      x = input_layer\n","      input_res = input_layer\n","\n","      for d in range(depth):\n","\n","          x = _inception_module(x)\n","\n","          if use_residual and d % 3 == 2:\n","              x = _shortcut_layer(input_res, x)\n","              input_res = x\n","\n","      gap_layer = keras.layers.GlobalAveragePooling1D()(x)\n","\n","      output_layer = keras.layers.Dense(nb_classes, activation='softmax')(gap_layer)\n","\n","      model = keras.models.Model(inputs=input_layer, outputs=output_layer)\n","\n","      model.compile(loss='categorical_crossentropy', optimizer='adam',\n","                      metrics=['accuracy'])\n","\n","\n","\n","      return model\n","\n","\n","\n","input_shape = [18, 30000]             #1 channel and 12-hours records\n","nb_classes = 2                        #MDD of Healthy\n","nb_filters = 64\n","verbose= True\n","use_residual = True\n","use_bottleneck = True\n","depth = 6\n","kernel_size = 41 - 1\n","batch_size = 32\n","mini_batch_size = 32\n","bottleneck_size = 64\n","nb_epochs = 1500\n","\n","\n","reduce_lr = ReduceLROnPlateau(monitor='val_accuracy', patience=30, factor=0.25, mode='max', \n","                                      verbose=1, min_lr=0.01)\n","\n","es = EarlyStopping(monitor='val_accuracy', mode='max', verbose=1, patience=100)\n","\n","\n","model_checkpoint = keras.callbacks.ModelCheckpoint(filepath=f'{model_folder}/my_model.h5', monitor='loss',save_best_only=True)\n","\n","callbacks = [reduce_lr, model_checkpoint,es]\n","\n","model = build_model(input_shape, nb_classes)\n","\n","hist = model.fit(X_train, y_train, batch_size=mini_batch_size, epochs=nb_epochs,  validation_data=(X_test, y_test), shuffle=True,verbose=verbose, callbacks = callbacks)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":415},"id":"8-PfdWR9RWAn","executionInfo":{"status":"error","timestamp":1682377863652,"user_tz":-210,"elapsed":38714,"user":{"displayName":"AIA Team","userId":"16477440184016990512"}},"outputId":"979e6ed7-7853-4d9e-d1e6-e20aa3043976"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/1500\n","14/14 [==============================] - 32s 2s/step - loss: 0.9479 - accuracy: 0.5532 - val_loss: 3.0148 - val_accuracy: 0.4057 - lr: 0.0010\n","Epoch 2/1500\n"," 1/14 [=>............................] - ETA: 28s - loss: 0.6290 - accuracy: 0.6875"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-16-9948fd21a6f9>\u001b[0m in \u001b[0;36m<cell line: 97>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m \u001b[0mhist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmini_batch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnb_epochs\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1683\u001b[0m                         ):\n\u001b[1;32m   1684\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1685\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1686\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1687\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 894\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    895\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    896\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    924\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    925\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 926\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    927\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    141\u001b[0m       (concrete_function,\n\u001b[1;32m    142\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m--> 143\u001b[0;31m     return concrete_function._call_flat(\n\u001b[0m\u001b[1;32m    144\u001b[0m         filtered_flat_args, captured_inputs=concrete_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1755\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1756\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1757\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1758\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1759\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    379\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 381\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    382\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     53\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"markdown","source":["# **Inference**"],"metadata":{"id":"IKSNb-RMsEbK"}},{"cell_type":"code","source":["!rm -r /content/example/test_outputs"],"metadata":{"id":"ikhTVQA88GJg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#model_folder\n","data_folder = \"/content/example/test_data\"\n","output_folder = \"/content/example/test_outputs\"\n","verbose = True\n","allow_failures = False"],"metadata":{"id":"2oeoyy03q39G","executionInfo":{"status":"ok","timestamp":1682377870975,"user_tz":-210,"elapsed":465,"user":{"displayName":"AIA Team","userId":"16477440184016990512"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["################################# edit this\n","import tensorflow as tf\n","\n","def load_challenge_models(model_folder, verbose):\n","    filename = os.path.join(model_folder, 'my_model.h5')\n","    return tf.keras.models.load_model(filename)"],"metadata":{"id":"4GN8XBN5syqZ","executionInfo":{"status":"ok","timestamp":1682377872241,"user_tz":-210,"elapsed":2,"user":{"displayName":"AIA Team","userId":"16477440184016990512"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["################ start test"],"metadata":{"id":"c6MdJd6Nu1MM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# patient_metadata, recording_metadata, recording_data = load_challenge_data(data_folder, \"ICARE_0284\")\n","\n","# eeg_data = get_EEG(recording_data)\n","# total = 0\n","# for i in range(18):\n","#   filtered_EEG = butter_bandpass_filter(np.array(eeg_data[i]),lowcut, highcut, fs, order)\n","#   total += filtered_EEG  \n","# f, t, Zxx = signal.stft(np.array(total), fs, nperseg=1000)\n","# amp = np.abs(np.mean(total))\n","# plt.pcolormesh(t, f, np.abs(Zxx), vmin=0, vmax=amp, shading='gouraud')\n","# img_path = f'{patient_id}.png'\n","# plt.savefig(img_path)\n","\n","# img = cv2.imread(img_path)\n","# img = cv2.resize(img, (IMAGE_HEIGHT, IMAGE_WIDTH))\n","# os.remove(img_path)"],"metadata":{"id":"TUG-csghvB4i"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# img.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3jDDzDjqvMWw","executionInfo":{"status":"ok","timestamp":1681978749429,"user_tz":-210,"elapsed":435,"user":{"displayName":"AIA Team","userId":"16477440184016990512"}},"outputId":"b94a63ed-c004-4184-a84a-26b89a30eaff"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["TensorShape([1, 256, 256, 3])"]},"metadata":{},"execution_count":57}]},{"cell_type":"code","source":["# img = tf.expand_dims(img, 0)"],"metadata":{"id":"MzYcmML_vV61"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# result = classifier.predict(img)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ubRuEt1tu4QL","executionInfo":{"status":"ok","timestamp":1681978768177,"user_tz":-210,"elapsed":456,"user":{"displayName":"AIA Team","userId":"16477440184016990512"}},"outputId":"82a2fc5d-0e56-4115-fc1a-4b03bba609e7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 66ms/step\n"]}]},{"cell_type":"code","source":["# result"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hr6PfeYkv0X-","executionInfo":{"status":"ok","timestamp":1681979413163,"user_tz":-210,"elapsed":511,"user":{"displayName":"AIA Team","userId":"16477440184016990512"}},"outputId":"c2e9c9b6-8427-4e98-c634-bcabb1afb6f1"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[0.9880442 , 0.01195578]], dtype=float32)"]},"metadata":{},"execution_count":63}]},{"cell_type":"code","source":["# outcome = np.argmax(result)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tEmt3xIBv8jO","executionInfo":{"status":"ok","timestamp":1681978849742,"user_tz":-210,"elapsed":575,"user":{"displayName":"AIA Team","userId":"16477440184016990512"}},"outputId":"17cb4717-43ed-4ec8-fa9f-8f4ebbbb7638"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0"]},"metadata":{},"execution_count":61}]},{"cell_type":"code","source":["# good_prob = result[0][0]"],"metadata":{"id":"eIjLEG5iy7s5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# outcome_probability = result[0][1]"],"metadata":{"id":"SOmoWwujyKBn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# good_prob = 0.658588"],"metadata":{"id":"uFNl5-1uzX2f"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# if good_prob >=0.8:\n","#     cpc = 1\n","# elif good_prob >=0.6:\n","#     cpc = 2\n","# elif good_prob >=0.4:\n","#     cpc = 3\n","# elif good_prob >=0.2:\n","#     cpc = 4\n","# else: \n","#     cpc = 5"],"metadata":{"id":"XtfFI2fzyuTA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["################ end test"],"metadata":{"id":"oODZXRYZu3Dr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["models = load_challenge_models(model_folder, verbose)"],"metadata":{"id":"kPGR_8oJYsUf","executionInfo":{"status":"ok","timestamp":1682375369524,"user_tz":-210,"elapsed":5407,"user":{"displayName":"AIA Team","userId":"16477440184016990512"}}},"execution_count":46,"outputs":[]},{"cell_type":"code","source":["sub_root_mat = []\n","p = os.path.join(data_folder,\"ICARE_0284\")\n","p1 = os.listdir(p)\n","for y in p1:\n","  z = os.path.join(p,y)\n","  if z.endswith('.mat'):\n","    sub_root_mat.append(z) "],"metadata":{"id":"hGHR_vrKYXbA","executionInfo":{"status":"ok","timestamp":1682375315637,"user_tz":-210,"elapsed":551,"user":{"displayName":"AIA Team","userId":"16477440184016990512"}}},"execution_count":45,"outputs":[]},{"cell_type":"code","source":["results = []\n","for x in sub_root_mat:\n","    a = loadmat(x)['val']\n","    a = tf.expand_dims(a, 0)\n","    result = models.predict(a, verbose=0)\n","    outcome = np.argmax(result)\n","    results.append(outcome)"],"metadata":{"id":"1M5sFViNZWKS","executionInfo":{"status":"ok","timestamp":1682375757661,"user_tz":-210,"elapsed":12043,"user":{"displayName":"AIA Team","userId":"16477440184016990512"}}},"execution_count":56,"outputs":[]},{"cell_type":"code","source":["results = np.array(results)"],"metadata":{"id":"_45i8hCpaVOZ","executionInfo":{"status":"ok","timestamp":1682376457162,"user_tz":-210,"elapsed":306,"user":{"displayName":"AIA Team","userId":"16477440184016990512"}}},"execution_count":70,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"9eXKzHfcc4Pw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["total = results.size"],"metadata":{"id":"wIKroBtTa0rH","executionInfo":{"status":"ok","timestamp":1682376235329,"user_tz":-210,"elapsed":308,"user":{"displayName":"AIA Team","userId":"16477440184016990512"}}},"execution_count":67,"outputs":[]},{"cell_type":"code","source":["good_count = np.sum(results == 0)\n","poor_count = np.sum(results == 1)"],"metadata":{"id":"vPcjo_Q4ap4E","executionInfo":{"status":"ok","timestamp":1682375969863,"user_tz":-210,"elapsed":458,"user":{"displayName":"AIA Team","userId":"16477440184016990512"}}},"execution_count":64,"outputs":[]},{"cell_type":"code","source":["outcome = 0 if good_count >= poor_count else 1"],"metadata":{"id":"wfdZYjyvbhuH","executionInfo":{"status":"ok","timestamp":1682376169168,"user_tz":-210,"elapsed":360,"user":{"displayName":"AIA Team","userId":"16477440184016990512"}}},"execution_count":65,"outputs":[]},{"cell_type":"code","source":["good_prob = float(good_count / total)\n","outcome_probability = float(poor_count / total)"],"metadata":{"id":"Y3FlDaKBb4Tn","executionInfo":{"status":"ok","timestamp":1682376259913,"user_tz":-210,"elapsed":858,"user":{"displayName":"AIA Team","userId":"16477440184016990512"}}},"execution_count":69,"outputs":[]},{"cell_type":"code","source":["a =  loadmat(sub_root_mat[0])['val']"],"metadata":{"id":"80dp4yubYxyO","executionInfo":{"status":"ok","timestamp":1682375580291,"user_tz":-210,"elapsed":3,"user":{"displayName":"AIA Team","userId":"16477440184016990512"}}},"execution_count":54,"outputs":[]},{"cell_type":"code","source":["a = tf.expand_dims(a, 0)"],"metadata":{"id":"tcOGTQ7FY8yq","executionInfo":{"status":"ok","timestamp":1682375435355,"user_tz":-210,"elapsed":315,"user":{"displayName":"AIA Team","userId":"16477440184016990512"}}},"execution_count":50,"outputs":[]},{"cell_type":"code","source":["result = models.predict(a)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QxHXMSHPY5dK","executionInfo":{"status":"ok","timestamp":1682375469260,"user_tz":-210,"elapsed":32005,"user":{"displayName":"AIA Team","userId":"16477440184016990512"}},"outputId":"1a051288-7dd8-4dc9-cdbe-b1d4b9207c7f"},"execution_count":51,"outputs":[{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 32s 32s/step\n"]}]},{"cell_type":"code","source":["result"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"THVzZBuPZABg","executionInfo":{"status":"ok","timestamp":1682375469260,"user_tz":-210,"elapsed":13,"user":{"displayName":"AIA Team","userId":"16477440184016990512"}},"outputId":"4783ac6c-396f-4125-96be-607fa029febc"},"execution_count":52,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[0.67552423, 0.32447574]], dtype=float32)"]},"metadata":{},"execution_count":52}]},{"cell_type":"code","source":["outcome = np.argmax(result)"],"metadata":{"id":"toPZ0HOpZJlM","executionInfo":{"status":"ok","timestamp":1682375484095,"user_tz":-210,"elapsed":2,"user":{"displayName":"AIA Team","userId":"16477440184016990512"}}},"execution_count":53,"outputs":[]},{"cell_type":"code","source":["\n","\n","good_prob = result[0][0]\n","outcome_probability = result[0][1]"],"metadata":{"id":"QlSZWCgMYhl0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["################################# edit this\n","def run_challenge_models(models, data_folder, patient_id, verbose):\n","\n","\n","    sub_root_mat = []\n","    p = os.path.join(data_folder,patient_id)\n","    p1 = os.listdir(p)\n","    for y in p1:\n","      z = os.path.join(p,y)\n","      if z.endswith('.mat'):\n","        sub_root_mat.append(z) \n","    \n","    results = []\n","    for x in sub_root_mat:\n","        a = loadmat(x)['val']\n","        a = tf.expand_dims(a, 0)\n","        result = models.predict(a, verbose=0)\n","        outcome = np.argmax(result)\n","        results.append(outcome)\n","        \n","    results = np.array(results)\n","\n","    total = results.size\n","\n","    if total > 0:\n","\n","        good_count = np.sum(results == 0)\n","        poor_count = np.sum(results == 1)\n","\n","        outcome = 0 if good_count >= poor_count else 1\n","\n","        good_prob = float(good_count / total)\n","        outcome_probability = float(poor_count / total)\n","\n","        if good_prob >=0.8:\n","            cpc = 1\n","        elif good_prob >=0.6:\n","            cpc = 2\n","        elif good_prob >=0.4:\n","            cpc = 3\n","        elif good_prob >=0.2:\n","            cpc = 4\n","        else: \n","            cpc = 5\n","\n","        cpc = np.clip(cpc, 1, 5)\n","\n","        return outcome, outcome_probability, cpc\n","    else:\n","        return float(0), float(0.5), float(2.5)"],"metadata":{"id":"OpD62mnDuG46","executionInfo":{"status":"ok","timestamp":1682377877236,"user_tz":-210,"elapsed":834,"user":{"displayName":"AIA Team","userId":"16477440184016990512"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["models = load_challenge_models(model_folder, verbose)"],"metadata":{"id":"jrPULtENtVVf","executionInfo":{"status":"ok","timestamp":1682377882234,"user_tz":-210,"elapsed":2953,"user":{"displayName":"AIA Team","userId":"16477440184016990512"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":["patient_ids = find_data_folders(data_folder)\n","num_patients = len(patient_ids)"],"metadata":{"id":"v-v8fhEWtugb","executionInfo":{"status":"ok","timestamp":1682377891138,"user_tz":-210,"elapsed":335,"user":{"displayName":"AIA Team","userId":"16477440184016990512"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","source":["os.makedirs(output_folder, exist_ok=True)"],"metadata":{"id":"hIXXEYkEt0Uf","executionInfo":{"status":"ok","timestamp":1682377883344,"user_tz":-210,"elapsed":2,"user":{"displayName":"AIA Team","userId":"16477440184016990512"}}},"execution_count":21,"outputs":[]},{"cell_type":"code","source":["# Iterate over the patients.\n","for i in range(num_patients):\n","    if verbose >= 2:\n","        print('    {}/{}...'.format(i+1, num_patients))\n","\n","    patient_id = patient_ids[i]\n","\n","    # Allow or disallow the models to fail on parts of the data; this can be helpful for debugging.\n","    try:\n","        outcome_binary, outcome_probability, cpc = run_challenge_models(models, data_folder, patient_id, verbose) ### Teams: Implement this function!!!\n","    except:\n","        if allow_failures:\n","            if verbose >= 2:\n","                print('... failed.')\n","            outcome_binary, outcome_probability, cpc = float('nan'), float('nan'), float('nan')\n","        else:\n","            raise\n","\n","    # Save Challenge outputs.\n","\n","    # Create a folder for the Challenge outputs if it does not already exist.\n","    os.makedirs(os.path.join(output_folder, patient_id), exist_ok=True)\n","    output_file = os.path.join(output_folder, patient_id, patient_id + '.txt')\n","    save_challenge_outputs(output_file, patient_id, outcome_binary, outcome_probability, cpc)"],"metadata":{"id":"d_XLqYUJt6Qt","executionInfo":{"status":"ok","timestamp":1682377909702,"user_tz":-210,"elapsed":17457,"user":{"displayName":"AIA Team","userId":"16477440184016990512"}}},"execution_count":24,"outputs":[]},{"cell_type":"markdown","source":["# **Evaluate Helper**"],"metadata":{"id":"HZ15a1u3A1vQ"}},{"cell_type":"code","source":["def evaluate_model(label_folder, output_folder):\n","    # Load labels and model outputs.\n","    patient_ids, label_outcomes, label_cpcs = load_challenge_labels(label_folder)\n","    output_outcomes, output_outcome_probabilities, output_cpcs = load_challenge_outputs(output_folder, patient_ids)\n","\n","    # Evaluate the models.\n","    challenge_score = compute_challenge_score(label_outcomes, output_outcome_probabilities)\n","    auroc_outcomes, auprc_outcomes = compute_auc(label_outcomes, output_outcome_probabilities)\n","    accuracy_outcomes, _, _ = compute_accuracy(label_outcomes, output_outcomes)\n","    f_measure_outcomes, _, _ = compute_f_measure(label_outcomes, output_outcomes)\n","\n","    mse_cpcs = compute_mse(label_cpcs, output_cpcs)\n","    mae_cpcs = compute_mae(label_cpcs, output_cpcs)\n","\n","    # Return the results.\n","    return challenge_score, auroc_outcomes, auprc_outcomes, accuracy_outcomes, f_measure_outcomes, mse_cpcs, mae_cpcs\n","\n","# Compute the Challenge score.\n","def compute_challenge_score(labels, outputs):\n","    assert len(labels) == len(outputs)\n","    num_instances = len(labels)\n","\n","    # Use the unique output values as the thresholds for the positive and negative classes.\n","    thresholds = np.unique(outputs)\n","    thresholds = np.append(thresholds, thresholds[-1]+1)\n","    thresholds = thresholds[::-1]\n","    num_thresholds = len(thresholds)\n","\n","    idx = np.argsort(outputs)[::-1]\n","\n","    # Initialize the TPs, FPs, FNs, and TNs with no positive outputs.\n","    tp = np.zeros(num_thresholds)\n","    fp = np.zeros(num_thresholds)\n","    fn = np.zeros(num_thresholds)\n","    tn = np.zeros(num_thresholds)\n","\n","    tp[0] = 0\n","    fp[0] = 0\n","    fn[0] = np.sum(labels == 1)\n","    tn[0] = np.sum(labels == 0)\n","\n","    # Update the TPs, FPs, FNs, and TNs using the values at the previous threshold.\n","    i = 0\n","    for j in range(1, num_thresholds):\n","        tp[j] = tp[j-1]\n","        fp[j] = fp[j-1]\n","        fn[j] = fn[j-1]\n","        tn[j] = tn[j-1]\n","\n","        while i < num_instances and outputs[idx[i]] >= thresholds[j]:\n","            if labels[idx[i]]:\n","                tp[j] += 1\n","                fn[j] -= 1\n","            else:\n","                fp[j] += 1\n","                tn[j] -= 1\n","            i += 1\n","\n","    # Compute the TPRs and FPRs.\n","    tpr = np.zeros(num_thresholds)\n","    fpr = np.zeros(num_thresholds)\n","    for j in range(num_thresholds):\n","        if tp[j] + fn[j] > 0:\n","            tpr[j] = float(tp[j]) / float(tp[j] + fn[j])\n","            fpr[j] = float(fp[j]) / float(fp[j] + tn[j])\n","        else:\n","            tpr[j] = float('nan')\n","            fpr[j] = float('nan')\n","\n","    # Find the largest TPR such that FPR <= 0.05.\n","    max_fpr = 0.05\n","    max_tpr = float('nan')\n","    if np.any(fpr <= max_fpr):\n","        indices = np.where(fpr <= max_fpr)\n","        max_tpr = np.max(tpr[indices])\n","\n","    return max_tpr\n","\n","# Compute area under the receiver operating characteristic curve (AUROC) and area under the precision recall curve (AUPRC).\n","def compute_auc(labels, outputs):\n","    assert len(labels) == len(outputs)\n","    num_instances = len(labels)\n","\n","    # Use the unique output values as the thresholds for the positive and negative classes.\n","    thresholds = np.unique(outputs)\n","    thresholds = np.append(thresholds, thresholds[-1]+1)\n","    thresholds = thresholds[::-1]\n","    num_thresholds = len(thresholds)\n","\n","    idx = np.argsort(outputs)[::-1]\n","\n","    # Initialize the TPs, FPs, FNs, and TNs with no positive outputs.\n","    tp = np.zeros(num_thresholds)\n","    fp = np.zeros(num_thresholds)\n","    fn = np.zeros(num_thresholds)\n","    tn = np.zeros(num_thresholds)\n","\n","    tp[0] = 0\n","    fp[0] = 0\n","    fn[0] = np.sum(labels == 1)\n","    tn[0] = np.sum(labels == 0)\n","\n","    # Update the TPs, FPs, FNs, and TNs using the values at the previous threshold.\n","    i = 0\n","    for j in range(1, num_thresholds):\n","        tp[j] = tp[j-1]\n","        fp[j] = fp[j-1]\n","        fn[j] = fn[j-1]\n","        tn[j] = tn[j-1]\n","\n","        while i < num_instances and outputs[idx[i]] >= thresholds[j]:\n","            if labels[idx[i]]:\n","                tp[j] += 1\n","                fn[j] -= 1\n","            else:\n","                fp[j] += 1\n","                tn[j] -= 1\n","            i += 1\n","\n","    # Compute the TPRs, TNRs, and PPVs at each threshold.\n","    tpr = np.zeros(num_thresholds)\n","    tnr = np.zeros(num_thresholds)\n","    ppv = np.zeros(num_thresholds)\n","    for j in range(num_thresholds):\n","        if tp[j] + fn[j]:\n","            tpr[j] = float(tp[j]) / float(tp[j] + fn[j])\n","        else:\n","            tpr[j] = float('nan')\n","        if fp[j] + tn[j]:\n","            tnr[j] = float(tn[j]) / float(fp[j] + tn[j])\n","        else:\n","            tnr[j] = float('nan')\n","        if tp[j] + fp[j]:\n","            ppv[j] = float(tp[j]) / float(tp[j] + fp[j])\n","        else:\n","            ppv[j] = float('nan')\n","\n","    # Compute AUROC as the area under a piecewise linear function with TPR/sensitivity (x-axis) and TNR/specificity (y-axis) and\n","    # AUPRC as the area under a piecewise constant with TPR/recall (x-axis) and PPV/precision (y-axis).\n","    auroc = 0.0\n","    auprc = 0.0\n","    for j in range(num_thresholds-1):\n","        auroc += 0.5 * (tpr[j+1] - tpr[j]) * (tnr[j+1] + tnr[j])\n","        auprc += (tpr[j+1] - tpr[j]) * ppv[j+1]\n","\n","    return auroc, auprc\n","\n","# Construct the one-hot encoding of data for the given classes.\n","def compute_one_hot_encoding(data, classes):\n","    num_instances = len(data)\n","    num_classes = len(classes)\n","\n","    one_hot_encoding = np.zeros((num_instances, num_classes), dtype=np.bool_)\n","    unencoded_data = list()\n","    for i, x in enumerate(data):\n","        for j, y in enumerate(classes):\n","            if (x == y) or (is_nan(x) and is_nan(y)):\n","                one_hot_encoding[i, j] = 1\n","\n","    return one_hot_encoding\n","\n","# Compute the binary confusion matrix, where the columns are the expert labels and the rows are the classifier labels for the given\n","# classes.\n","def compute_confusion_matrix(labels, outputs, classes):\n","    assert np.shape(labels) == np.shape(outputs)\n","\n","    num_instances = len(labels)\n","    num_classes = len(classes)\n","\n","    A = np.zeros((num_classes, num_classes))\n","    for k in range(num_instances):\n","        for i in range(num_classes):\n","            for j in range(num_classes):\n","                if outputs[k, i] == 1 and labels[k, j] == 1:\n","                    A[i, j] += 1\n","\n","    return A\n","\n","# Construct the binary one-vs-rest confusion matrices, where the columns are the expert labels and the rows are the classifier\n","# for the given classes.\n","def compute_one_vs_rest_confusion_matrix(labels, outputs, classes):\n","    assert np.shape(labels) == np.shape(outputs)\n","\n","    num_instances = len(labels)\n","    num_classes = len(classes)\n","\n","    A = np.zeros((num_classes, 2, 2))\n","    for i in range(num_instances):\n","        for j in range(num_classes):\n","            if labels[i, j] == 1 and outputs[i, j] == 1: # TP\n","                A[j, 0, 0] += 1\n","            elif labels[i, j] == 0 and outputs[i, j] == 1: # FP\n","                A[j, 0, 1] += 1\n","            elif labels[i, j] == 1 and outputs[i, j] == 0: # FN\n","                A[j, 1, 0] += 1\n","            elif labels[i, j] == 0 and outputs[i, j] == 0: # TN\n","                A[j, 1, 1] += 1\n","\n","    return A\n","\n","# Compute accuracy.\n","def compute_accuracy(labels, outputs):\n","    # Compute the confusion matrix.\n","    classes = np.unique(np.concatenate((labels, outputs)))\n","    labels = compute_one_hot_encoding(labels, classes)\n","    outputs = compute_one_hot_encoding(outputs, classes)\n","    A = compute_confusion_matrix(labels, outputs, classes)\n","\n","    # Compute accuracy.\n","    if np.sum(A) > 0:\n","        accuracy = np.trace(A) / np.sum(A)\n","    else:\n","        accuracy = float('nan')\n","\n","    # Compute per-class accuracy.\n","    num_classes = len(classes)\n","    per_class_accuracy = np.zeros(num_classes)\n","    for i in range(num_classes):\n","        if np.sum(labels[:, i]) > 0:\n","            per_class_accuracy[i] = A[i, i] / np.sum(A[:, i])\n","        else:\n","            per_class_accuracy[i] = float('nan')\n","\n","    return accuracy, per_class_accuracy, classes\n","\n","# Compute macro F-measure.\n","def compute_f_measure(labels, outputs):\n","    # Compute confusion matrix.\n","    classes = np.unique(np.concatenate((labels, outputs)))\n","    labels = compute_one_hot_encoding(labels, classes)\n","    outputs = compute_one_hot_encoding(outputs, classes)\n","    A = compute_one_vs_rest_confusion_matrix(labels, outputs, classes)\n","\n","    num_classes = len(classes)\n","    per_class_f_measure = np.zeros(num_classes)\n","    for k in range(num_classes):\n","        tp, fp, fn, tn = A[k, 0, 0], A[k, 0, 1], A[k, 1, 0], A[k, 1, 1]\n","        if 2 * tp + fp + fn > 0:\n","            per_class_f_measure[k] = float(2 * tp) / float(2 * tp + fp + fn)\n","        else:\n","            per_class_f_measure[k] = float('nan')\n","\n","    if np.any(np.isfinite(per_class_f_measure)):\n","        macro_f_measure = np.nanmean(per_class_f_measure)\n","    else:\n","        macro_f_measure = float('nan')\n","\n","    return macro_f_measure, per_class_f_measure, classes\n","\n","# Compute mean-squared error.\n","def compute_mse(labels, outputs):\n","    assert len(labels) == len(outputs)\n","\n","    labels = np.asarray(labels, dtype=np.float64)\n","    outputs = np.asarray(outputs, dtype=np.float64)\n","    mse = np.mean((labels - outputs)**2)\n","\n","    return mse\n","\n","# Compute mean-absolute error.\n","def compute_mae(labels, outputs):\n","    assert len(labels) == len(outputs)\n","\n","    labels = np.asarray(labels, dtype=np.float64)\n","    outputs = np.asarray(outputs, dtype=np.float64)\n","    mae = np.mean(np.abs(labels - outputs))\n","\n","    return mae"],"metadata":{"id":"rqT8lHymA3hf","executionInfo":{"status":"ok","timestamp":1682377917111,"user_tz":-210,"elapsed":653,"user":{"displayName":"AIA Team","userId":"16477440184016990512"}}},"execution_count":25,"outputs":[]},{"cell_type":"markdown","source":["# **Evaluate**"],"metadata":{"id":"AjZLjnpTAiZM"}},{"cell_type":"code","source":["test_data = \"/content/example/test_data\"\n","test_outputs = \"/content/example/test_outputs\""],"metadata":{"id":"31Z-uKhfAlvU","executionInfo":{"status":"ok","timestamp":1682377919320,"user_tz":-210,"elapsed":4,"user":{"displayName":"AIA Team","userId":"16477440184016990512"}}},"execution_count":26,"outputs":[]},{"cell_type":"code","source":["scores = evaluate_model(test_data, test_outputs)\n","\n","# Unpack the scores.\n","challenge_score, auroc_outcomes, auprc_outcomes, accuracy_outcomes, f_measure_outcomes, mse_cpcs, mae_cpcs = scores\n","\n","# Construct a string with scores.\n","output_string = \\\n","    'Challenge Score: {:.3f}\\n'.format(challenge_score) + \\\n","    'Outcome AUROC: {:.3f}\\n'.format(auroc_outcomes) + \\\n","    'Outcome AUPRC: {:.3f}\\n'.format(auprc_outcomes) + \\\n","    'Outcome Accuracy: {:.3f}\\n'.format(accuracy_outcomes) + \\\n","    'Outcome F-measure: {:.3f}\\n'.format(f_measure_outcomes) + \\\n","    'CPC MSE: {:.3f}\\n'.format(mse_cpcs) + \\\n","    'CPC MAE: {:.3f}\\n'.format(mae_cpcs)\n","\n","print(output_string)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"W_3qeLtHATsL","executionInfo":{"status":"ok","timestamp":1682377919320,"user_tz":-210,"elapsed":3,"user":{"displayName":"AIA Team","userId":"16477440184016990512"}},"outputId":"81dbdf4b-7265-41a6-9615-cc326a5d3dc2"},"execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["Challenge Score: 0.000\n","Outcome AUROC: 0.200\n","Outcome AUPRC: 0.200\n","Outcome Accuracy: 0.167\n","Outcome F-measure: 0.143\n","CPC MSE: 10.708\n","CPC MAE: 3.083\n","\n"]}]},{"cell_type":"code","source":["!rm -r /content/example/test_data/.ipynb_checkpoints/"],"metadata":{"id":"YiyB2LXRESxL"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Test For Submission**"],"metadata":{"id":"s52z-cYK7ErM"}},{"cell_type":"code","source":["!ls"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CIcjFbf77I1T","executionInfo":{"status":"ok","timestamp":1682006361459,"user_tz":-210,"elapsed":559,"user":{"displayName":"AIA Team","userId":"16477440184016990512"}},"outputId":"de920268-3e64-4d61-87f0-619c22595f51"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["4.zip  aa.zip  drive  example  sample_data\n"]}]},{"cell_type":"code","source":["!pip install mne"],"metadata":{"id":"-zXdsboZHMtl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%cd /content"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ONGmLkCI7JKm","executionInfo":{"status":"ok","timestamp":1682006377459,"user_tz":-210,"elapsed":4,"user":{"displayName":"AIA Team","userId":"16477440184016990512"}},"outputId":"88529221-fbac-4820-86e9-e8055dff3fb6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content\n"]}]},{"cell_type":"code","source":["!unzip /content/inc.zip"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4ZBzn3_M-e50","executionInfo":{"status":"ok","timestamp":1682377975200,"user_tz":-210,"elapsed":359,"user":{"displayName":"AIA Team","userId":"16477440184016990512"}},"outputId":"7804db69-4a5b-4fcb-d84a-d546280bd4d4"},"execution_count":29,"outputs":[{"output_type":"stream","name":"stdout","text":["Archive:  /content/inc.zip\n","   creating: python-example-2023-master/\n","  inflating: python-example-2023-master/Dockerfile  \n","  inflating: python-example-2023-master/evaluate_model.py  \n","  inflating: python-example-2023-master/helper_code.py  \n","  inflating: python-example-2023-master/LICENSE  \n","  inflating: python-example-2023-master/README.md  \n","  inflating: python-example-2023-master/remove_data.py  \n","  inflating: python-example-2023-master/remove_labels.py  \n","  inflating: python-example-2023-master/requirements.txt  \n","  inflating: python-example-2023-master/run_model.py  \n","  inflating: python-example-2023-master/team_code.py  \n","  inflating: python-example-2023-master/train_model.py  \n","  inflating: python-example-2023-master/truncate_data.py  \n"]}]},{"cell_type":"code","source":["%cd /content/python-example-2023-master"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZfEjEVU47O4T","executionInfo":{"status":"ok","timestamp":1682377986092,"user_tz":-210,"elapsed":373,"user":{"displayName":"AIA Team","userId":"16477440184016990512"}},"outputId":"5f065916-7276-4233-b3c6-3f92bb0ad7e0"},"execution_count":30,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/python-example-2023-master\n"]}]},{"cell_type":"code","source":["!rm -r /content/example/test_outputs"],"metadata":{"id":"qFkI93yciw78","executionInfo":{"status":"ok","timestamp":1682378008028,"user_tz":-210,"elapsed":502,"user":{"displayName":"AIA Team","userId":"16477440184016990512"}}},"execution_count":31,"outputs":[]},{"cell_type":"code","source":["!python train_model.py /content/example/training_data /content/example/model"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6Kjislyy7SFn","executionInfo":{"status":"ok","timestamp":1682379129954,"user_tz":-210,"elapsed":204708,"user":{"displayName":"AIA Team","userId":"16477440184016990512"}},"outputId":"13a8001d-3275-41b3-bcfc-0ecbd662af41"},"execution_count":36,"outputs":[{"output_type":"stream","name":"stdout","text":["2023-04-24 23:28:48.134921: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","Finding the Challenge data...\n","Extracting features and labels from the Challenge data...\n","2023-04-24 23:30:36.185704: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 456840000 exceeds 10% of free system memory.\n","Epoch 1/1500\n","14/14 [==============================] - 32s 2s/step - loss: 0.9779 - accuracy: 0.5697 - val_loss: 61.6258 - val_accuracy: 0.6415 - lr: 0.0010\n","Epoch 2/1500\n","14/14 [==============================] - 23s 2s/step - loss: 0.4290 - accuracy: 0.8463 - val_loss: 4.4000 - val_accuracy: 0.6509 - lr: 0.0010\n","Epoch 3/1500\n","14/14 [==============================] - 22s 2s/step - loss: 0.3126 - accuracy: 0.8865 - val_loss: 0.8407 - val_accuracy: 0.5377 - lr: 0.0010\n","Epoch 4/1500\n"," 6/14 [===========>..................] - ETA: 13s - loss: 0.2725 - accuracy: 0.9167Traceback (most recent call last):\n","  File \"/content/python-example-2023-master/train_model.py\", line 30, in <module>\n","    train_challenge_model(data_folder, model_folder, verbose) ### Teams: Implement this function!!!\n","  File \"/content/python-example-2023-master/team_code.py\", line 178, in train_challenge_model\n","    hist = model.fit(X_train, y_train, batch_size=mini_batch_size, epochs=nb_epochs,  validation_data=(X_test, y_test), shuffle=True,verbose=verbose, callbacks = callbacks)\n","  File \"/usr/local/lib/python3.9/dist-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n","    return fn(*args, **kwargs)\n","  File \"/usr/local/lib/python3.9/dist-packages/keras/engine/training.py\", line 1685, in fit\n","    tmp_logs = self.train_function(iterator)\n","  File \"/usr/local/lib/python3.9/dist-packages/tensorflow/python/util/traceback_utils.py\", line 150, in error_handler\n","    return fn(*args, **kwargs)\n","  File \"/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\", line 894, in __call__\n","    result = self._call(*args, **kwds)\n","  File \"/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\", line 926, in _call\n","    return self._no_variable_creation_fn(*args, **kwds)  # pylint: disable=not-callable\n","  File \"/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\", line 143, in __call__\n","    return concrete_function._call_flat(\n","  File \"/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\", line 1757, in _call_flat\n","    return self._build_call_outputs(self._inference_function.call(\n","  File \"/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\", line 381, in call\n","    outputs = execute.execute(\n","  File \"/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/execute.py\", line 52, in quick_execute\n","    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n","KeyboardInterrupt\n","^C\n"]}]},{"cell_type":"code","source":["!python run_model.py /content/example/model /content/example/test_data /content/example/test_outputs"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tfRAE6kB71Ew","executionInfo":{"status":"ok","timestamp":1682379164899,"user_tz":-210,"elapsed":25658,"user":{"displayName":"AIA Team","userId":"16477440184016990512"}},"outputId":"251c46de-9c7e-4403-a8c3-99d588540d47"},"execution_count":37,"outputs":[{"output_type":"stream","name":"stdout","text":["2023-04-24 23:32:20.947704: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","Loading the Challenge models...\n","Finding the Challenge data...\n","Running the Challenge models on the Challenge data...\n","Done.\n"]}]},{"cell_type":"code","source":["!python evaluate_model.py /content/example/test_data /content/example/test_outputs"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"to-xgFwgGdn2","executionInfo":{"status":"ok","timestamp":1682379242943,"user_tz":-210,"elapsed":1225,"user":{"displayName":"AIA Team","userId":"16477440184016990512"}},"outputId":"828f4913-e7df-4395-9886-13dda30f436a"},"execution_count":38,"outputs":[{"output_type":"stream","name":"stdout","text":["Challenge Score: 0.000\n","Outcome AUROC: 0.400\n","Outcome AUPRC: 0.250\n","Outcome Accuracy: 0.333\n","Outcome F-measure: 0.250\n","CPC MSE: 5.375\n","CPC MAE: 2.083\n","\n"]}]},{"cell_type":"code","source":["python evaluate_model.py test_data test_outputs"],"metadata":{"id":"RTEfXUAEGdwB"},"execution_count":null,"outputs":[]}]}